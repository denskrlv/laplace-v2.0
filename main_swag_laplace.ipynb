{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SWAG-Laplace Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from datetime import datetime\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision.models import resnet18\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from laplace.curvature.asdl import AsdlGGN\n",
    "from laplace.marglik_training import marglik_training\n",
    "from laplace.swag_laplace import SWAGLaplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "DATA_ROOT = './data'\n",
    "BATCH_SIZE = 128\n",
    "LIKELIHOOD = 'classification'\n",
    "EPOCHS = 1\n",
    "MARGLIK_FREQUENCY = 1\n",
    "N_MODELS = 20\n",
    "\n",
    "# Create a directory to save models if it doesn't exist\n",
    "save_dir = './models'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Add this to the beginning of your notebook after imports\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Prepare dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "full_dataset = datasets.CIFAR10(root=DATA_ROOT, train=True, download=True, transform=transform)\n",
    "\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, drop_last=True)\n",
    "\n",
    "for inputs, targets in train_loader:\n",
    "    inputs, targets = inputs.to(device), targets.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Initialize and train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet18(weights='IMAGENET1K_V1')\n",
    "\n",
    "# Replace the final layer with one that outputs 10 classes for CIFAR-10\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Linear(num_features, 10)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# lap, trained_model, train_loss, val_loss = marglik_training(\n",
    "#     model=model,\n",
    "#     train_loader=train_loader,\n",
    "#     likelihood=LIKELIHOOD,\n",
    "#     n_epochs=EPOCHS,\n",
    "#     marglik_frequency=MARGLIK_FREQUENCY,\n",
    "#     hessian_structure='diag',\n",
    "#     backend=AsdlGGN,\n",
    "#     progress_bar=True,\n",
    "#     device=device\n",
    "# )\n",
    "\n",
    "# timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "# model_path = f\"{save_dir}/marglik_trained_model_{timestamp}.pkl\"\n",
    "\n",
    "# with open(model_path, 'wb') as f:\n",
    "#     pickle.dump({\n",
    "#         'model_state': trained_model.state_dict(),\n",
    "#         'training_params': {\n",
    "#             'epochs': EPOCHS,\n",
    "#             'likelihood': LIKELIHOOD,\n",
    "#             'marglik_frequency': MARGLIK_FREQUENCY\n",
    "#         }\n",
    "#     }, f)\n",
    "\n",
    "# print(f\"Marglik trained model saved to {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Initialize and train SWAG Laplace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs: 100%|██████████| 1/1 [02:29<00:00, 149.91s/it, loss=1.0837]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SWAG-Laplace model saved to ./models/swag_laplace_model_20250603_231150.pkl\n"
     ]
    }
   ],
   "source": [
    "swag_laplace = SWAGLaplace(\n",
    "    model=model,\n",
    "    likelihood=LIKELIHOOD,\n",
    "    n_models=N_MODELS,\n",
    "    start_epoch=0,\n",
    "    swa_freq=1,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "swag_laplace.fit(\n",
    "    train_loader=train_loader,\n",
    "    optimizer=torch.optim.Adam(model.parameters(), lr=1e-3),\n",
    "    criterion=criterion,\n",
    "    epochs=EPOCHS,\n",
    "    progress_bar=True,\n",
    ")\n",
    "\n",
    "train_accuracy = swag_laplace.evaluate(train_loader)\n",
    "val_accuracy = swag_laplace.evaluate(val_loader)\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "model_path = f\"{save_dir}/swag_laplace_model_{timestamp}.pkl\"\n",
    "\n",
    "with open(model_path, 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'swag_laplace_state': {\n",
    "            'model_state': model.state_dict(),\n",
    "            'swag_mean': swag_laplace.swag_mean,\n",
    "            'swag_covariance': swag_laplace.swag_covariance,\n",
    "        },\n",
    "        'training_params': {\n",
    "            'epochs': EPOCHS,\n",
    "            'likelihood': LIKELIHOOD,\n",
    "            'n_models': N_MODELS,\n",
    "            'accuracies': {\n",
    "                'train': train_accuracy,\n",
    "                'validation': val_accuracy\n",
    "            }\n",
    "        }\n",
    "    }, f)\n",
    "\n",
    "print(f\"SWAG-Laplace model saved to {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Get predictions using SWAG-Laplace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: ./models/swag_laplace_model_20250603_231150.pkl\n",
      "Loaded model train accuracy: 69.66%\n",
      "Loaded model validation accuracy: 68.62%\n",
      "Evaluating loaded model on validation data...\n",
      "Re-evaluated validation accuracy: 69.07%\n"
     ]
    }
   ],
   "source": [
    "saved_models = glob.glob(f\"{save_dir}/swag_laplace_model_*.pkl\")\n",
    "\n",
    "if not saved_models:\n",
    "    print(\"No saved models found!\")\n",
    "else:\n",
    "    model_path = max(saved_models, key=os.path.getctime)  # Get the most recent file\n",
    "    print(f\"Loading model from: {model_path}\")\n",
    "\n",
    "    # Load the saved model\n",
    "    with open(model_path, 'rb') as f:\n",
    "        saved_data = pickle.load(f)\n",
    "\n",
    "    # Create a new instance of your model\n",
    "    loaded_model = resnet18(weights='IMAGENET1K_V1')\n",
    "    num_features = loaded_model.fc.in_features\n",
    "    loaded_model.fc = nn.Linear(num_features, 10)\n",
    "    loaded_model.load_state_dict(saved_data['swag_laplace_state']['model_state'])\n",
    "    loaded_model = loaded_model.to(device)\n",
    "\n",
    "    # Create a new SWAGLaplace instance\n",
    "    loaded_swag_laplace = SWAGLaplace(\n",
    "        model=loaded_model,\n",
    "        likelihood=saved_data['training_params']['likelihood'],\n",
    "        n_models=saved_data['training_params']['n_models'],\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    # Restore SWAG statistics\n",
    "    loaded_swag_laplace.swag_mean = saved_data['swag_laplace_state']['swag_mean']\n",
    "    loaded_swag_laplace.swag_covariance = saved_data['swag_laplace_state']['swag_covariance']\n",
    "\n",
    "    # Get predictions using loaded model\n",
    "    test_inputs, test_targets = next(iter(val_loader))\n",
    "    test_inputs = test_inputs.to(device)\n",
    "\n",
    "    # Retrieve stored accuracies\n",
    "    train_accuracy = saved_data['training_params']['accuracies']['train']\n",
    "    val_accuracy = saved_data['training_params']['accuracies']['validation']\n",
    "    \n",
    "    print(f'Loaded model train accuracy: {train_accuracy:.2f}%')\n",
    "    print(f'Loaded model validation accuracy: {val_accuracy:.2f}%')\n",
    "    \n",
    "    # Optional: Verify the loaded model's performance\n",
    "    print(\"Evaluating loaded model on validation data...\")\n",
    "    loaded_val_accuracy = loaded_swag_laplace.evaluate(val_loader)\n",
    "    print(f'Re-evaluated validation accuracy: {loaded_val_accuracy:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
